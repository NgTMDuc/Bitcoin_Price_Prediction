{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8ecf48e"
   },
   "source": [
    "## **Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T02:58:03.108658Z",
     "iopub.status.busy": "2022-06-14T02:58:03.108281Z",
     "iopub.status.idle": "2022-06-14T02:58:03.115619Z",
     "shell.execute_reply": "2022-06-14T02:58:03.114647Z",
     "shell.execute_reply.started": "2022-06-14T02:58:03.108627Z"
    },
    "id": "e6ab4de9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, LSTM, BatchNormalization\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Binarizer\n",
    "\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x00bEpgqm6xK"
   },
   "source": [
    "## **Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the normalized data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"normalized_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the periods of time that the features have in the data**\n",
    "\n",
    "For example, the features contain SMA2 which is the smoothed moving average during 2 days, so a period of time that must be in the periods list is 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = [2,4,8,12,24,48,96,192]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label value counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop useless column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T01:35:27.899039Z",
     "iopub.status.busy": "2022-06-14T01:35:27.898441Z",
     "iopub.status.idle": "2022-06-14T01:35:27.91221Z",
     "shell.execute_reply": "2022-06-14T01:35:27.911394Z",
     "shell.execute_reply.started": "2022-06-14T01:35:27.898995Z"
    },
    "id": "ab5acb6c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop nan if exist**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all the amount of nan values\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or forward fill before drop, this forward filling can avoid data leakeage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T01:35:27.91399Z",
     "iopub.status.busy": "2022-06-14T01:35:27.913565Z",
     "iopub.status.idle": "2022-06-14T01:35:27.931798Z",
     "shell.execute_reply": "2022-06-14T01:35:27.931085Z",
     "shell.execute_reply.started": "2022-06-14T01:35:27.913947Z"
    }
   },
   "outputs": [],
   "source": [
    "forward_fill = False\n",
    "\n",
    "if forward_fill:\n",
    "    df.ffill(inplace=True)\n",
    "else:\n",
    "    df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create train set, validation set and test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T02:39:39.602282Z",
     "iopub.status.busy": "2022-06-14T02:39:39.601829Z",
     "iopub.status.idle": "2022-06-14T02:39:39.635586Z",
     "shell.execute_reply": "2022-06-14T02:39:39.63422Z",
     "shell.execute_reply.started": "2022-06-14T02:39:39.602245Z"
    },
    "id": "96fe034a"
   },
   "outputs": [],
   "source": [
    "# Convert all dataframes to numpy\n",
    "train_df = df.copy().iloc[0:int(len(df)*0.7),:]\n",
    "train_data_np = train_df.to_numpy()\n",
    "\n",
    "val_df = df.copy().iloc[int(len(df)*0.7):int(len(df)*0.85),:]\n",
    "val_data_np = val_df.to_numpy()\n",
    "\n",
    "test_df = df.copy().iloc[int(len(df)*0.85):].copy()\n",
    "test_data_np = test_df.copy().to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define window size**\n",
    "\n",
    "This is the amount of previous row data which should be included in the LSTM model for predicting the current row label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T01:36:07.479504Z",
     "iopub.status.busy": "2022-06-14T01:36:07.479095Z",
     "iopub.status.idle": "2022-06-14T01:36:07.48379Z",
     "shell.execute_reply": "2022-06-14T01:36:07.482802Z",
     "shell.execute_reply.started": "2022-06-14T01:36:07.479469Z"
    }
   },
   "outputs": [],
   "source": [
    "window_size = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split sequence function**\n",
    "\n",
    "This function is used for creating features and label, note that the label is already shifted, which means that it is derived by using the label (True of False) of 'next row close price > current row close price'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T01:36:07.871749Z",
     "iopub.status.busy": "2022-06-14T01:36:07.871316Z",
     "iopub.status.idle": "2022-06-14T01:36:07.877447Z",
     "shell.execute_reply": "2022-06-14T01:36:07.876781Z",
     "shell.execute_reply.started": "2022-06-14T01:36:07.871698Z"
    },
    "id": "77639621"
   },
   "outputs": [],
   "source": [
    "def split_sequences(data, window_size, label_col_idx):\n",
    "    x = []\n",
    "    y = []\n",
    "    tmp_data = np.concatenate((data[:,:label_col_idx], data[:,label_col_idx+1:]), axis=1)\n",
    "    \n",
    "    for i in range(-1,len(data)-window_size):\n",
    "        scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "        \n",
    "        # Take window_size rows data (including the current row, note that the label is already shifted)\n",
    "        x.append(scaler.fit_transform(tmp_data[i+1:i+window_size+1,:])) \n",
    "        \n",
    "        # To predict the current value of label column\n",
    "        y.append(data[i+window_size,label_col_idx]) \n",
    "        \n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T02:58:17.040454Z",
     "iopub.status.busy": "2022-06-14T02:58:17.040038Z",
     "iopub.status.idle": "2022-06-14T02:58:17.128618Z",
     "shell.execute_reply": "2022-06-14T02:58:17.127705Z",
     "shell.execute_reply.started": "2022-06-14T02:58:17.040417Z"
    },
    "id": "636f8c5a"
   },
   "outputs": [],
   "source": [
    "train_data_np = np.asarray(train_data_np).astype('float32')\n",
    "val_data_np = np.asarray(val_data_np).astype('float32')\n",
    "test_data_np = np.asarray(test_data_np).astype('float32')\n",
    "\n",
    "x_train, y_train = split_sequences(train_data_np, window_size, df.columns.get_loc(\"label\"))\n",
    "x_val, y_val = split_sequences(val_data_np, window_size, df.columns.get_loc(\"label\"))\n",
    "x_test, y_test = split_sequences(test_data_np, window_size, df.columns.get_loc(\"label\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model and training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T03:33:49.349839Z",
     "iopub.status.busy": "2022-06-14T03:33:49.349433Z",
     "iopub.status.idle": "2022-06-14T03:33:49.387169Z",
     "shell.execute_reply": "2022-06-14T03:33:49.38646Z",
     "shell.execute_reply.started": "2022-06-14T03:33:49.349803Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Build model...')\n",
    "\n",
    "class LSTM_model(Model):\n",
    "\n",
    "    def __init__(self, num_of_outputs:int=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.LSTM1 = LSTM(num_of_outputs, return_sequences=True, recurrent_dropout=0.3)\n",
    "        self.LSTM2 = LSTM(num_of_outputs, return_sequences=True, recurrent_dropout=0.3)\n",
    "        self.LSTM3 = LSTM(num_of_outputs, return_sequences=False, recurrent_dropout=0.3)\n",
    "        \n",
    "        self.batch_norm = BatchNormalization()\n",
    "        \n",
    "        self.dense = Dense(16, activation='relu')\n",
    "\n",
    "        self.out = Dense(1, activation='sigmoid')\n",
    "\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        x1 = self.LSTM1(inputs)\n",
    "        x1 = self.batch_norm(x1)\n",
    "        x2 = self.LSTM2(x1)\n",
    "        x2 = self.batch_norm(x2)\n",
    "        x3 = self.LSTM3(x2)\n",
    "        x4 = self.dense(x3)\n",
    "\n",
    "        return self.out(x4)\n",
    "\n",
    "model = LSTM_model()\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=15, \n",
    "                        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "print('Build model successfully')\n",
    "\n",
    "print(\"First fit before printing model summary: \")\n",
    "\n",
    "opt = Adam()\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['binary_crossentropy','accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=1, validation_data=(x_val, y_val))\n",
    "\n",
    "print(\"Model summary:\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Loss: Binary Cross Entropy\n",
    "+ Optimizer: Adam\n",
    "+ Metrics: Binary Cross Entropy and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T03:33:52.162724Z",
     "iopub.status.busy": "2022-06-14T03:33:52.162363Z"
    },
    "id": "d8d72d31",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Train...')\n",
    "\n",
    "opt = Adam()\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['binary_crossentropy','accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=100, validation_data=(x_val, y_val), callbacks=monitor)\n",
    "\n",
    "print('End of training phase')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_train, y_train);\n",
    "model.evaluate(x_val, y_val);\n",
    "model.evaluate(x_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Threshold tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = model.predict(x_val)\n",
    "tmp_pred_val = pred_val.copy()\n",
    "\n",
    "l = []\n",
    "for i in range(4000, 6000):\n",
    "    pred_val = (tmp_pred_val >= i/10000) * 1\n",
    "    l.append(accuracy_score(y_val, pred_val))\n",
    "\n",
    "threshold = max(l)\n",
    "print(max(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(x_test)\n",
    "pred_test = (pred_test >= threshold) * 1\n",
    "print(\"Final testing accuracy:\")\n",
    "accuracy_score(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "The result will depend on the early stopping strategy, in the reality, we train multiple times the model and choose the one that gives us the best accuracy on the validation set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
