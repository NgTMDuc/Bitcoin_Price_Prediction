{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T08:19:01.112502Z",
     "iopub.status.busy": "2022-06-15T08:19:01.112038Z",
     "iopub.status.idle": "2022-06-15T08:19:01.116984Z",
     "shell.execute_reply": "2022-06-15T08:19:01.115955Z",
     "shell.execute_reply.started": "2022-06-15T08:19:01.112469Z"
    },
    "id": "a8ecf48e"
   },
   "source": [
    "## **Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:50.292627Z",
     "iopub.status.busy": "2022-06-16T06:16:50.292005Z",
     "iopub.status.idle": "2022-06-16T06:16:50.302429Z",
     "shell.execute_reply": "2022-06-16T06:16:50.301258Z",
     "shell.execute_reply.started": "2022-06-16T06:16:50.292584Z"
    },
    "id": "e6ab4de9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "import random\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, LeakyReLU, Dense, Embedding, Dropout, LSTM, Input, BatchNormalization, Flatten, Bidirectional, Reshape, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "TF_ENABLE_ONEDNN_OPTS=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:50.309101Z",
     "iopub.status.busy": "2022-06-16T06:16:50.308744Z",
     "iopub.status.idle": "2022-06-16T06:16:50.318700Z",
     "shell.execute_reply": "2022-06-16T06:16:50.317310Z",
     "shell.execute_reply.started": "2022-06-16T06:16:50.309064Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:50.329909Z",
     "iopub.status.busy": "2022-06-16T06:16:50.329559Z",
     "iopub.status.idle": "2022-06-16T06:16:50.343959Z",
     "shell.execute_reply": "2022-06-16T06:16:50.342925Z",
     "shell.execute_reply.started": "2022-06-16T06:16:50.329880Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T08:14:34.311768Z",
     "iopub.status.busy": "2022-06-15T08:14:34.311034Z",
     "iopub.status.idle": "2022-06-15T08:14:34.317499Z",
     "shell.execute_reply": "2022-06-15T08:14:34.316238Z",
     "shell.execute_reply.started": "2022-06-15T08:14:34.311718Z"
    },
    "id": "x00bEpgqm6xK"
   },
   "source": [
    "## **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:50.367574Z",
     "iopub.status.busy": "2022-06-16T06:16:50.366819Z",
     "iopub.status.idle": "2022-06-16T06:16:51.794724Z",
     "shell.execute_reply": "2022-06-16T06:16:51.793916Z",
     "shell.execute_reply.started": "2022-06-16T06:16:50.367532Z"
    },
    "id": "V68YYgMunuQ8",
    "outputId": "6b1b3246-6225-4a9f-f60f-1c8ee16829a9"
   },
   "outputs": [],
   "source": [
    "file_path = \"../input/data-with-features-ver01/data_with_features_ver01.csv\"\n",
    "# file_path = \"data_with_features_ver01.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T08:14:35.715875Z",
     "iopub.status.busy": "2022-06-15T08:14:35.715508Z",
     "iopub.status.idle": "2022-06-15T08:14:35.726358Z",
     "shell.execute_reply": "2022-06-15T08:14:35.725267Z",
     "shell.execute_reply.started": "2022-06-15T08:14:35.715844Z"
    }
   },
   "source": [
    "#### Test naive method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:51.796677Z",
     "iopub.status.busy": "2022-06-16T06:16:51.796213Z",
     "iopub.status.idle": "2022-06-16T06:16:51.839184Z",
     "shell.execute_reply": "2022-06-16T06:16:51.838385Z",
     "shell.execute_reply.started": "2022-06-16T06:16:51.796647Z"
    }
   },
   "outputs": [],
   "source": [
    "a = df[(df[\"volume_SMA4\"] >= df[\"volume_SMA8\"])].index\n",
    "b = df[(df[\"volume_SMA4\"] < df[\"volume_SMA8\"])].index+1\n",
    "a_b = set(a).intersection(set(b))\n",
    "lst = sorted(list(a_b))\n",
    "print((df[\"close\"].to_numpy()[np.array(lst)+1] - df[\"close\"].to_numpy()[lst] >= 0).sum()/len(lst))\n",
    "print(len(lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T08:14:35.771648Z",
     "iopub.status.busy": "2022-06-15T08:14:35.771183Z",
     "iopub.status.idle": "2022-06-15T08:14:35.778006Z",
     "shell.execute_reply": "2022-06-15T08:14:35.776418Z",
     "shell.execute_reply.started": "2022-06-15T08:14:35.771607Z"
    }
   },
   "source": [
    "### **Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:54.882541Z",
     "iopub.status.busy": "2022-06-16T06:16:54.881813Z",
     "iopub.status.idle": "2022-06-16T06:16:56.545134Z",
     "shell.execute_reply": "2022-06-16T06:16:56.543796Z",
     "shell.execute_reply.started": "2022-06-16T06:16:54.882507Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = \"../input/data-with-features-ver01/data_with_features_ver01.csv\"\n",
    "original_df = pd.read_csv(file_path)\n",
    "original_df[\"price_diff\"] = original_df[\"close\"].copy()\n",
    "original_df.drop(columns=[\"Unnamed: 0\", \"Time_UTC_Start\", \"close\"], inplace=True)\n",
    "original_df.dropna()\n",
    "df = original_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:54.866422Z",
     "iopub.status.busy": "2022-06-16T06:16:54.865690Z",
     "iopub.status.idle": "2022-06-16T06:16:54.880696Z",
     "shell.execute_reply": "2022-06-16T06:16:54.879667Z",
     "shell.execute_reply.started": "2022-06-16T06:16:54.866389Z"
    },
    "id": "266417cc"
   },
   "outputs": [],
   "source": [
    "# df[\"day\"] = pd.to_datetime(df[\"Time_UTC_Start\"]).dt.day/31\n",
    "# df[\"month\"] = pd.to_datetime(df[\"Time_UTC_Start\"]).dt.month/12\n",
    "# df[\"year\"] = pd.to_datetime(df[\"Time_UTC_Start\"]).dt.year/2018\n",
    "# df[\"hour\"] = pd.to_datetime(df[\"Time_UTC_Start\"]).dt.hour/24\n",
    "\n",
    "# if diff_percentage == True:\n",
    "#     df[\"day\"] /= 100\n",
    "#     df[\"month\"] /= 100\n",
    "#     df[\"year\"] /= 100\n",
    "#     df[\"hour\"] /= 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:56.547002Z",
     "iopub.status.busy": "2022-06-16T06:16:56.546660Z",
     "iopub.status.idle": "2022-06-16T06:16:56.562042Z",
     "shell.execute_reply": "2022-06-16T06:16:56.561334Z",
     "shell.execute_reply.started": "2022-06-16T06:16:56.546965Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_normalization(df: DataFrame, days_range: int=20, include_cur_row: bool=False):\n",
    "    '''\n",
    "    Return the normalized data:\n",
    "    + df: the dataframe to be normalized\n",
    "    + range: the number of previous rows (or including the current row) to be considered in the normalization\n",
    "    + include_cur_row: True if we consider the current row in the normalization process (calculate mean and std\n",
    "    using the current row and (range-1) previous rows), False if we want to use all the passed data for normalization \n",
    "    processing ((calculate mean and std using (range) previous rows))\n",
    "    '''\n",
    "    \n",
    "    df_roll = None\n",
    "\n",
    "    if include_cur_row == False:\n",
    "        df_roll = df.rolling(days_range, closed='left')\n",
    "    else:\n",
    "        df_roll = df.rolling(days_range)\n",
    "        \n",
    "    res_df = (df - df_roll.mean()) / df_roll.std()\n",
    "    res_df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    res_df.dropna(inplace=True)\n",
    "    res_df.reset_index(drop=True, inplace=True)\n",
    "    return res_df\n",
    "\n",
    "\n",
    "def data_denormalization(predictions, original_df: DataFrame, steps: int, col_idx: int, days_range: int=20, include_cur_row: bool=False):\n",
    "    '''\n",
    "    Return the rescaled predictions data:\n",
    "    + df: the dataframe to be denormalized\n",
    "    + original_df: the dataframe used for denormalizing df before\n",
    "    + range: the number of previous rows (or including the current row) to be considered in the denormalization\n",
    "    + include_cur_row: True if we consider the current row in the denormalization process (calculate mean and std\n",
    "    using the current row and (range-1) previous rows), False if we want to use all the passed data for denormalization \n",
    "    processing ((calculate mean and std using (range) previous rows))\n",
    "    '''\n",
    "    \n",
    "    df_roll = None\n",
    "    if include_cur_row == False:\n",
    "        df_roll = original_df.rolling(days_range, closed='left')\n",
    "    else:\n",
    "        df_roll = original_df.rolling(days_range)\n",
    "    \n",
    "    res_df = original_df.copy()\n",
    "    res_df.iloc[20+steps:,col_idx] = predictions.reshape((-1))\n",
    "    res_df = res_df * df_roll.std() + df_roll.mean()\n",
    "\n",
    "    return res_df.iloc[20+steps:,col_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:56.563661Z",
     "iopub.status.busy": "2022-06-16T06:16:56.563228Z",
     "iopub.status.idle": "2022-06-16T06:16:57.241837Z",
     "shell.execute_reply": "2022-06-16T06:16:57.240999Z",
     "shell.execute_reply.started": "2022-06-16T06:16:56.563632Z"
    }
   },
   "outputs": [],
   "source": [
    "df = data_normalization(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:57.243959Z",
     "iopub.status.busy": "2022-06-16T06:16:57.243359Z",
     "iopub.status.idle": "2022-06-16T06:16:57.255064Z",
     "shell.execute_reply": "2022-06-16T06:16:57.254031Z",
     "shell.execute_reply.started": "2022-06-16T06:16:57.243915Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert all dataframes to numpy\n",
    "norm_train_df = df.iloc[0:int(len(df)*0.7),:]\n",
    "train_df = original_df.iloc[:int(len(df)*0.7)+20,:]\n",
    "train_data = norm_train_df.to_numpy()\n",
    "num_rows_train, num_cols_train = train_data.shape\n",
    "\n",
    "norm_val_df = df.iloc[int(len(df)*0.7):int(len(df)*0.8),:]\n",
    "val_df = original_df.iloc[int(len(df)*0.7):int(len(df)*0.8)+20,:]\n",
    "val_data = norm_val_df.to_numpy()\n",
    "num_rows_val, num_cols_val = val_data.shape\n",
    "\n",
    "norm_test_df = df.iloc[int(len(df)*0.8):]\n",
    "test_df = original_df.iloc[int(len(df)*0.8):,:]\n",
    "test_data = norm_test_df.to_numpy()\n",
    "num_rows_test, num_cols_test = test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:57.257305Z",
     "iopub.status.busy": "2022-06-16T06:16:57.256699Z",
     "iopub.status.idle": "2022-06-16T06:16:57.300658Z",
     "shell.execute_reply": "2022-06-16T06:16:57.299929Z",
     "shell.execute_reply.started": "2022-06-16T06:16:57.257262Z"
    }
   },
   "outputs": [],
   "source": [
    "norm_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:57.302339Z",
     "iopub.status.busy": "2022-06-16T06:16:57.301846Z",
     "iopub.status.idle": "2022-06-16T06:16:57.314165Z",
     "shell.execute_reply": "2022-06-16T06:16:57.313359Z",
     "shell.execute_reply.started": "2022-06-16T06:16:57.302295Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = np.asarray(norm_train_df).astype('float32')\n",
    "val_data = np.asarray(norm_val_df).astype('float32')\n",
    "test_data = np.asarray(norm_test_df).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:57.316116Z",
     "iopub.status.busy": "2022-06-16T06:16:57.315487Z",
     "iopub.status.idle": "2022-06-16T06:16:57.319478Z",
     "shell.execute_reply": "2022-06-16T06:16:57.318775Z",
     "shell.execute_reply.started": "2022-06-16T06:16:57.316084Z"
    }
   },
   "outputs": [],
   "source": [
    "steps = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T07:41:04.719098Z",
     "iopub.status.busy": "2022-06-15T07:41:04.718724Z",
     "iopub.status.idle": "2022-06-15T07:41:04.722553Z",
     "shell.execute_reply": "2022-06-15T07:41:04.721854Z",
     "shell.execute_reply.started": "2022-06-15T07:41:04.719069Z"
    }
   },
   "source": [
    "### Split sequence by window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:57.321346Z",
     "iopub.status.busy": "2022-06-16T06:16:57.320837Z",
     "iopub.status.idle": "2022-06-16T06:16:57.333019Z",
     "shell.execute_reply": "2022-06-16T06:16:57.332338Z",
     "shell.execute_reply.started": "2022-06-16T06:16:57.321292Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_sequences(data, window_size, price_diff_col_idx):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(0,len(data)-window_size):\n",
    "        x.append(data[i:i+window_size,:]) # Take window_size rows data before\n",
    "        y.append(data[i+window_size,price_diff_col_idx]) # To predict the current value of label colume\n",
    "    return np.array(x), np.array(y).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T07:41:07.183262Z",
     "iopub.status.busy": "2022-06-15T07:41:07.18288Z",
     "iopub.status.idle": "2022-06-15T07:41:07.187837Z",
     "shell.execute_reply": "2022-06-15T07:41:07.187071Z",
     "shell.execute_reply.started": "2022-06-15T07:41:07.183233Z"
    }
   },
   "source": [
    "### Split sequence for GAN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:57.334867Z",
     "iopub.status.busy": "2022-06-16T06:16:57.334368Z",
     "iopub.status.idle": "2022-06-16T06:16:57.345840Z",
     "shell.execute_reply": "2022-06-16T06:16:57.345088Z",
     "shell.execute_reply.started": "2022-06-16T06:16:57.334836Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_sequences_gan(data, window_size, price_diff_col_idx):\n",
    "    x = []\n",
    "    for i in range(0,len(data)-window_size):\n",
    "        x.append(data[i:i+window_size+1,price_diff_col_idx])\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:57.347707Z",
     "iopub.status.busy": "2022-06-16T06:16:57.347160Z",
     "iopub.status.idle": "2022-06-16T06:16:57.546838Z",
     "shell.execute_reply": "2022-06-16T06:16:57.546005Z",
     "shell.execute_reply.started": "2022-06-16T06:16:57.347675Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train_gan = split_sequences_gan(train_data, steps, df.columns.get_loc(\"price_diff\"))\n",
    "\n",
    "x_train, y_train = split_sequences(train_data, steps, df.columns.get_loc(\"price_diff\"))\n",
    "x_val, y_val = split_sequences(val_data, steps, df.columns.get_loc(\"price_diff\"))\n",
    "x_test, y_test = split_sequences(test_data, steps, df.columns.get_loc(\"price_diff\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:57.548964Z",
     "iopub.status.busy": "2022-06-16T06:16:57.548464Z",
     "iopub.status.idle": "2022-06-16T06:16:57.552506Z",
     "shell.execute_reply": "2022-06-16T06:16:57.551753Z",
     "shell.execute_reply.started": "2022-06-16T06:16:57.548931Z"
    },
    "id": "d1b39f59"
   },
   "outputs": [],
   "source": [
    "num_of_outputs = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T07:41:10.25811Z",
     "iopub.status.busy": "2022-06-15T07:41:10.257669Z",
     "iopub.status.idle": "2022-06-15T07:41:10.262673Z",
     "shell.execute_reply": "2022-06-15T07:41:10.261634Z",
     "shell.execute_reply.started": "2022-06-15T07:41:10.258074Z"
    }
   },
   "source": [
    "## **Original model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:57.554002Z",
     "iopub.status.busy": "2022-06-16T06:16:57.553614Z",
     "iopub.status.idle": "2022-06-16T06:16:57.566611Z",
     "shell.execute_reply": "2022-06-16T06:16:57.565629Z",
     "shell.execute_reply.started": "2022-06-16T06:16:57.553974Z"
    }
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "mae = tf.keras.losses.MeanAbsoluteError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:57.568525Z",
     "iopub.status.busy": "2022-06-16T06:16:57.568180Z",
     "iopub.status.idle": "2022-06-16T06:16:57.583721Z",
     "shell.execute_reply": "2022-06-16T06:16:57.582663Z",
     "shell.execute_reply.started": "2022-06-16T06:16:57.568494Z"
    }
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return 3*mae(y_train.reshape((-1,1)),generator(x_train)) + cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:57.587888Z",
     "iopub.status.busy": "2022-06-16T06:16:57.587543Z",
     "iopub.status.idle": "2022-06-16T06:16:57.597969Z",
     "shell.execute_reply": "2022-06-16T06:16:57.596904Z",
     "shell.execute_reply.started": "2022-06-16T06:16:57.587859Z"
    }
   },
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T07:02:57.002266Z",
     "iopub.status.busy": "2022-06-15T07:02:57.00165Z",
     "iopub.status.idle": "2022-06-15T07:02:57.005963Z",
     "shell.execute_reply": "2022-06-15T07:02:57.004977Z",
     "shell.execute_reply.started": "2022-06-15T07:02:57.002231Z"
    }
   },
   "source": [
    "### **1. Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:57.599865Z",
     "iopub.status.busy": "2022-06-16T06:16:57.599219Z",
     "iopub.status.idle": "2022-06-16T06:16:57.632871Z",
     "shell.execute_reply": "2022-06-16T06:16:57.631943Z",
     "shell.execute_reply.started": "2022-06-16T06:16:57.599830Z"
    }
   },
   "outputs": [],
   "source": [
    "class GeneratorModel(Model):\n",
    "    def __init__(self, num_of_outputs:int):\n",
    "        super().__init__()\n",
    "        self.t2v_first_col = Dense(1, input_shape=(steps,df.shape[-1]), activation=None)\n",
    "        self.t2v_others_col = Dense(255, input_shape=(steps,df.shape[-1]), activation=None)\n",
    "        self.LSTM1 = LSTM(num_of_outputs, return_sequences=True, recurrent_dropout=0.3)\n",
    "        self.LSTM2 = LSTM(num_of_outputs, return_sequences=True, recurrent_dropout=0.3)\n",
    "        self.LSTM3 = LSTM(num_of_outputs, return_sequences=False, recurrent_dropout=0.3)\n",
    "        self.batch_norm1 = BatchNormalization()\n",
    "        self.batch_norm2 = BatchNormalization()\n",
    "        self.Dense1 = Dense(32)\n",
    "        self.Dense2 = Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        t2v_x1 = self.t2v_first_col(inputs)\n",
    "        t2v_x2 = tf.sin(self.t2v_others_col(inputs))\n",
    "        t2v = tf.concat([t2v_x1,t2v_x2],-1)\n",
    "        x1 = self.LSTM1(t2v)\n",
    "        x1 = self.batch_norm1(x1)\n",
    "        x2 = self.LSTM2(x1)\n",
    "        x2 = self.batch_norm1(x2)\n",
    "        x3 = self.LSTM3(x2)\n",
    "        x4 = self.Dense1(x3)\n",
    "        x5 = self.batch_norm2(x4)\n",
    "        return self.Dense2(x5)\n",
    "        \n",
    "        \n",
    "generator = GeneratorModel(num_of_outputs=num_of_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T07:02:57.543616Z",
     "iopub.status.busy": "2022-06-15T07:02:57.542799Z",
     "iopub.status.idle": "2022-06-15T07:02:57.549369Z",
     "shell.execute_reply": "2022-06-15T07:02:57.54851Z",
     "shell.execute_reply.started": "2022-06-15T07:02:57.543577Z"
    }
   },
   "source": [
    "### **2. Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:57.635113Z",
     "iopub.status.busy": "2022-06-16T06:16:57.634270Z",
     "iopub.status.idle": "2022-06-16T06:16:57.657390Z",
     "shell.execute_reply": "2022-06-16T06:16:57.656620Z",
     "shell.execute_reply.started": "2022-06-16T06:16:57.635056Z"
    }
   },
   "outputs": [],
   "source": [
    "class DiscriminatorModel(Model):\n",
    "    def __init__(self, num_of_outputs:int):\n",
    "        super().__init__()\n",
    "        self.Reshape = Reshape((steps+1,1))\n",
    "#         self.Bidirectional_LSTM1 = Bidirectional(LSTM(num_of_outputs, return_sequences=False))\n",
    "        self.batch_norm1 = BatchNormalization()\n",
    "        self.batch_norm2 = BatchNormalization()\n",
    "        self.batch_norm3 = BatchNormalization()\n",
    "        self.batch_norm4 = BatchNormalization()\n",
    "#         self.Dense1 = Dense(512, activation=tf.keras.layers.LeakyReLU(alpha=0.01))\n",
    "        self.Dense2 = Dense(128, activation=tf.keras.layers.LeakyReLU(alpha=0.01))\n",
    "        self.Dense3 = Dense(32, activation=tf.keras.layers.LeakyReLU(alpha=0.01))\n",
    "        self.Dense4 = Dense(1, activation='sigmoid')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x0 = self.Reshape(inputs)\n",
    "#         x1 = self.Bidirectional_LSTM1(x0)\n",
    "#         x1 = self.batch_norm1(x1)\n",
    "#         x2 = self.Dense1(x0)\n",
    "#         x2 = self.batch_norm2(x2)\n",
    "        x3 = self.Dense2(x0)\n",
    "        x3 = self.batch_norm3(x3)\n",
    "        x4 = self.Dense3(x3)\n",
    "        x4 = self.batch_norm4(x4)\n",
    "        return self.Dense4(x4)\n",
    "        \n",
    "discriminator = DiscriminatorModel(num_of_outputs=num_of_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:57.659226Z",
     "iopub.status.busy": "2022-06-16T06:16:57.658444Z",
     "iopub.status.idle": "2022-06-16T06:16:57.664211Z",
     "shell.execute_reply": "2022-06-16T06:16:57.663444Z",
     "shell.execute_reply.started": "2022-06-16T06:16:57.659194Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_fake_samples(x, generator, price_diff_col_idx):\n",
    "    pred = generator(x)\n",
    "    return Concatenate(axis=1)([x[:,:,df.columns.get_loc(\"price_diff\")],pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:57.666450Z",
     "iopub.status.busy": "2022-06-16T06:16:57.665777Z",
     "iopub.status.idle": "2022-06-16T06:16:57.677158Z",
     "shell.execute_reply": "2022-06-16T06:16:57.676385Z",
     "shell.execute_reply.started": "2022-06-16T06:16:57.666418Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_idx_data(x_train, rate=0.5):\n",
    "    faked_idx = np.random.randint(0, x_train.shape[0], int(x_train.shape[0]*rate))\n",
    "    real_idx = np.array(list(set([i for i in range(x_train.shape[0])]).difference(set(faked_idx))))\n",
    "    return faked_idx, real_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T06:16:57.679313Z",
     "iopub.status.busy": "2022-06-16T06:16:57.678435Z",
     "iopub.status.idle": "2022-06-16T06:16:57.692089Z",
     "shell.execute_reply": "2022-06-16T06:16:57.691386Z",
     "shell.execute_reply.started": "2022-06-16T06:16:57.679282Z"
    }
   },
   "outputs": [],
   "source": [
    "generator_optimizer = adam\n",
    "discriminator_optimizer = adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T07:49:37.495561Z",
     "iopub.status.busy": "2022-06-16T07:49:37.494977Z",
     "iopub.status.idle": "2022-06-16T07:50:38.700703Z",
     "shell.execute_reply": "2022-06-16T07:50:38.699937Z",
     "shell.execute_reply.started": "2022-06-16T07:49:37.495528Z"
    }
   },
   "outputs": [],
   "source": [
    "generator.compile(loss=\"mae\")\n",
    "for i in range(5):\n",
    "    print(\"i =\", i, \":\")\n",
    "    faked_idx, real_idx = generate_idx_data(x_train)\n",
    "    x_real = x_train_gan[real_idx]\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        x_faked = generate_fake_samples(x_train[faked_idx], generator, df.columns.get_loc(\"price_diff\"))\n",
    "        real_output = discriminator(x_real, training=True)\n",
    "        fake_output = discriminator(x_faked, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    print(\"Generator loss %s | Discriminator loss %s\" %(float(gen_loss), float(disc_loss)))\n",
    "    print(\"Val loss evaluation\", generator.evaluate(x_val,y_val))\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T07:50:38.702748Z",
     "iopub.status.busy": "2022-06-16T07:50:38.702045Z",
     "iopub.status.idle": "2022-06-16T07:50:50.589723Z",
     "shell.execute_reply": "2022-06-16T07:50:50.588146Z",
     "shell.execute_reply.started": "2022-06-16T07:50:38.702712Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_train = generator.predict(x_train)\n",
    "predictions_train = data_denormalization(predictions_train, original_df=train_df, steps=steps, col_idx=df.columns.get_loc(\"price_diff\"))\n",
    "y_real_train = train_df[\"price_diff\"][20+steps:].reset_index(drop=True)\n",
    "print(\"Train Accuracy:\",((y_real_train - y_real_train.shift(1))*(predictions_train.to_numpy()-y_real_train.shift(1).to_numpy())>0).sum()/predictions_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T07:50:50.591440Z",
     "iopub.status.busy": "2022-06-16T07:50:50.591109Z",
     "iopub.status.idle": "2022-06-16T07:50:52.480924Z",
     "shell.execute_reply": "2022-06-16T07:50:52.479814Z",
     "shell.execute_reply.started": "2022-06-16T07:50:50.591412Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_val = generator.predict(x_val)\n",
    "predictions_val = data_denormalization(predictions_val, original_df=val_df, steps=steps, col_idx=df.columns.get_loc(\"price_diff\"))\n",
    "y_real_val = val_df[\"price_diff\"][20+steps:].reset_index(drop=True)\n",
    "print(\"Validation Accuracy:\",((y_real_val - y_real_val.shift(1))*(predictions_val.to_numpy()-y_real_val.shift(1).to_numpy())>0).sum()/predictions_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T07:50:52.483056Z",
     "iopub.status.busy": "2022-06-16T07:50:52.482692Z",
     "iopub.status.idle": "2022-06-16T07:50:56.112136Z",
     "shell.execute_reply": "2022-06-16T07:50:56.111408Z",
     "shell.execute_reply.started": "2022-06-16T07:50:52.483025Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_test = generator.predict(x_test)\n",
    "predictions_test = data_denormalization(predictions_test, original_df=test_df, steps=steps, col_idx=df.columns.get_loc(\"price_diff\"))\n",
    "y_real_test = test_df[\"price_diff\"][20+steps:].reset_index(drop=True)\n",
    "print(\"Test Accuracy:\",((y_real_test - y_real_test.shift(1))*(predictions_test.to_numpy()-y_real_test.shift(1).to_numpy())>0).sum()/predictions_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T07:50:56.113843Z",
     "iopub.status.busy": "2022-06-16T07:50:56.113356Z",
     "iopub.status.idle": "2022-06-16T07:50:56.404383Z",
     "shell.execute_reply": "2022-06-16T07:50:56.403667Z",
     "shell.execute_reply.started": "2022-06-16T07:50:56.113809Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9), dpi=90)\n",
    "plt.plot(np.arange(100), predictions_test[0:100], label=\"predictions\")\n",
    "plt.plot(np.arange(100), y_real_test[0:100], label=\"real\")\n",
    "plt.legend()  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
